{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # 将图像转换为张量\n",
    "])\n",
    "\n",
    "# 加载训练集\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 设置随机种子以确保结果可复现\n",
    "random.seed(42)\n",
    "\n",
    "# 随机选择一些图像的索引\n",
    "num_samples = 5  # 选择5张图像\n",
    "random_indices = random.sample(range(len(train_dataset)), num_samples)\n",
    "\n",
    "# 创建一个子图画布\n",
    "fig, axes = plt.subplots(1, num_samples, figsize=(12, 3))\n",
    "\n",
    "# 显示随机选择的图像\n",
    "for i, idx in enumerate(random_indices):\n",
    "    image, label = train_dataset[idx]  # 获取图像和标签\n",
    "    axes[i].imshow(image.squeeze(), cmap='gray')  # 显示图像（去掉批次维度）\n",
    "    axes[i].set_title(f\"Label: {label}\")  # 设置标题为标签\n",
    "    axes[i].axis('off')  # 关闭坐标轴\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5的架构如下：\n",
    "\n",
    "输入层：32x32的灰度图像（MNIST图像会被调整为32x32）。\n",
    "\n",
    "卷积层1：6个5x5的卷积核，输出6个28x28的特征图。\n",
    "\n",
    "池化层1：2x2的最大池化，输出6个14x14的特征图。\n",
    "\n",
    "卷积层2：16个5x5的卷积核，输出16个10x10的特征图。\n",
    "\n",
    "池化层2：2x2的最大池化，输出16个5x5的特征图。\n",
    "\n",
    "全连接层1：120个神经元。\n",
    "\n",
    "全连接层2：84个神经元。\n",
    "\n",
    "输出层：10个神经元（对应10个类别）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 卷积层1：输入1通道，输出6通道，卷积核5x5\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        # 池化层1：2x2最大池化\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 卷积层2：输入6通道，输出16通道，卷积核5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        # 池化层2：2x2最大池化\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 全连接层1：输入16*5*5=400，输出120\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        # 全连接层2：输入120，输出84\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 输出层：输入84，输出10\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 卷积层1 + ReLU + 池化层1\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        # 卷积层2 + ReLU + 池化层2\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # 展平操作\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        # 全连接层1 + ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 全连接层2 + ReLU\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # 输出层\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST数据集中的图像大小为28x28，而LeNet-5的输入要求是32x32。因此，我们需要将图像调整为32x32。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理：将图像调整为32x32，转换为张量，并进行归一化\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # 调整图像大小为32x32\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST的均值和标准差\n",
    "])\n",
    "\n",
    "# 加载训练集和测试集\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=False, transform=transform)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)  # 使用交叉熵损失函数\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet5().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./lenet5_mnist.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 加载模型并进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5().to(device)\n",
    "model.load_state_dict(torch.load(\"lenet5_mnist.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# 使用测试集中的数据进行预测\n",
    "with torch.no_grad():\n",
    "    data, target = next(iter(test_loader))\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    print(f'Predicted: {pred[0].item()}, Actual: {target[0].item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orientor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
